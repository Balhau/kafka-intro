<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Apache Kafka</title>

		<meta name="description" content="An Apache Kafka introduction">
		<meta name="author" content="VÃ­tor Fernandes">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section data-markdown>
					<textarea data-template>
						# Apache Kafka
						
						## The distributed log

						Created by [Apache Kafka](https://github.com/apache/kafka)

						[Balhau](http://codecorner.balhau.net)
					</textarea>
                </section>
                

                <section>
                    <section data-markdown>
                        <textarea data-template>
                                ## In the beginning of time
                        </textarea>
                    </section>
                    <section data-markdown>
                        <textarea data-template>
                                ## The dinossaur era
                                The web was formed by *http server* responding with static content
                        </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## The three cake layer
                                    After some time web applications become *dynamic* 
                                    * With a three layer architecture

                                    ![Three layer Architecture](img/threelayer1.png)
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## But then Internet had grown...
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## The monolith
                                    Monolithic approach had some drawbacks
                                    * Difficult to maintain
                                    * Difficult to scale
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## Microservices to the rescue
                                    To overcome the scalling and mantainability issues monoliths start to be broken into
                                    a microservice architecture
                                    ![Microservices vs Monoliths](img/monovsmicro.jpg)
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## The HTTP contract
                                    Orchestraction of microservices follow a [REST](https://en.wikipedia.org/wiki/Representational_state_transfer)
                                    approach
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## Microservice architecture
                                    ![Microservices architecture](img/metricsmicro1.png)
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## But then...
                                    Microservices are heterogeneous
                                    * Some are quick
                                    * Others not so...                                    
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## Scale the slower ones
                                    ![Scale the microservice](img/scalehttp1.png)
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## But sometimes...
                                    * You can't
                                    * You don't need
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## And the world went async
                                    * Async REST contracts
                                    * Fire and Forget
                                    ![Async vs Sync](img/asyncvssync.png)
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## And then the queue
                                    Async solutions need a way to store the messages submited to processing
                                    * First internal queues
                                    * But the internal queues had local visibility would not horizontally scale
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                    ## External queues
                                    Orchestration of async microservices start using external queue services
                                    * Enable multiple publishers
                                    * Enable multiple consumers
                            </textarea>
                    </section>
                    <section data-markdown>
                        <textarea data-template>
                                ![Pub Sub v1](img/rabbitmq1.jpg)
                        </textarea>
                    </section>
                    <section>
                            <h2>The Queue Era</h2>
                            <p>Several queue implementation mechanisms arrive to solve the world</p>
                            <img src="img/rabbitmq.png" width="50%"/>
                            <img src="img/activemq.png"/>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                ## But then things got messy...
                            </textarea>
                    </section>

                    <section data-markdown>
                            <textarea data-template>
                                ## Queues...
                                * Don't scale horizontally
                                * Don't persist data easily
                                * Don't shard
                                * Multiple publisher/subscriber is hard
                            </textarea>
                    </section>
                    
                    <section data-markdown>
                            <textarea data-template>
                                ## What is wrong then?
                                * Queues implementation are memory oriented, memory is volatile.
                                * Queue paradigm is based on the principle that one puts other gests
                                    * With multiple subscribers some of them fail... *some for very long*
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                ## Reallity
                                Multiple pub/sub is hard to do on queues.
                            </textarea>
                    </section>
                </section>
                <section>
                    <section data-markdown>
                        <textarea data-template>
                            ## ... and then what?
                        </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                ## Wouldn't be nice if...
                                * Some mechanism solve the queue drawbacks?
                                * Even better if this already exist...
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                ## It exists!
                                * Yes, at least from [1981](https://people.eecs.berkeley.edu/~brewer/cs262/SystemR.pdf)
                                * Its called log 
                            </textarea>
                    </section>

                    <section data-markdown>
                            <textarea data-template>
                                ## Cool, but...
                                * What is a log?
                                * How does it solve the problems?
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                ## The Log
                                ![Anatomy of a Log](img/log1.png)
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                ## The key idea
                                * On queues one *puts* another *picks*
                                * On logs on *puts* another *reads*
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                ## The write/read
                                The log write/read (as oposed to put/get) has several advantages over queues
                                * Don't need synchronization between clients because we don't remove as soon as all
                                consumer read the message.
                                * If another consumer wants to join he will have the messages to *read* with queues they were
                                consumed and hence not available
                                * Durability is straightforward, everything is on disc.
                            </textarea>
                    </section>
                    <section data-markdown>
                            <textarea data-template>
                                ## But will it scale?
                                Not this simple log.
                            </textarea>
                    </section>
                    <section id="fragments">
                            <h2>But a distributed log will</h2>
                            <p class="fragment">Is there anyone</p>
                            <p class="fragment">This exactly what <a href="">Apache Kakfa</a> is</p>
                    </section>
                </section>
                <section>
                        <section data-markdown>
                                <textarea data-template>
                                    ## What is *Apache Kafka*?
                                </textarea>
                        </section>
                        <section data-markdown>
                            <textarea data-template>
                                Apache KafkaÂ® is a distributed streaming platform
                            </textarea>
                        </section>
                        <section data-markdown>
                                <textarea data-template>
                                        ## What does this even mean?
                                </textarea>
                        </section>
                        <section data-markdown>
                                <textarea data-template>
                                        ## A streaming platform has three key capabilities:
                                        * Publish and subscribe to streams of records, 
                                        similar to a message queue or enterprise messaging system.
                                        * Store streams of records in a fault-tolerant durable way.
                                        * Process streams of records as they occur. 
                                </textarea>
                        </section>
                        <section data-markdown>
                                <textarea data-template>
                                        ## Why the name *Kafka*?
                                </textarea>
                        </section>
                        <section data-markdown>
                                <textarea data-template>
                                *I thought that since Kafka was a system optimized for writing, using a writerâs name
                                would make sense. I had taken a lot of lit classes in college and liked Franz Kafka. Plus
                                the name sounded cool for an open source project.
                                So basically there is not much of a relationship.*

                                [Jay Kreps](https://www.linkedin.com/in/jaykreps/)
                                </textarea>
                        </section>
                        <section data-markdown>
                                <textarea data-template>
                                    ## Kafka Architecture
                                    ![Apache Kafka](img/kafkapubsub1.png)
                                </textarea>
                        </section>
                        <section data-markdown>
                                <textarea data-template>
                                    ## Kafka Topic
                                    ![Apache Kafka](img/kafkatopic2.png)
                                </textarea>
                        </section>
                        <section data-markdown>
                                <textarea data-template>
                                    ## The consumer group
                                    ![Apache Kafka](img/consumergroup.png)
                                </textarea>
                        </section>
                        <section data-markdown>
                                <textarea data-template>
                                    ## The partition/replication on *Kafka*
                                </textarea>
                        </section>
                        <section data-markdown>
                                <textarea data-template>
                                    ![Apache Kafka](img/partitionreplication.png)
                                </textarea>
                        </section>
		</section>
		
		<section>
			<section data-markdown>
                                <textarea data-template>
				    ## Building Kafka data Pipelines
				    Some principles we should *take care*
                                </textarea>
			</section>
			<section data-markdown>
                                <textarea data-template>
				    ## Timeliness 
				    Producers and consumers will have different *timeliness* requirements
				    * Look at Kafka in this context is that it acts as a giant buffer that decouâ
				    ples the time-sensitivity requirements between producers and consumers.*
                                </textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
				    ## Reliability
				    Validate your delivery guarantees
				    * Kafka gives you at *least semantics*
				    * With the help of ACID datastores you can achieve *exactly once* semantics
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					## High and Varying throughput
					Kafka *push/pull* model enables you to decouple producer and consumer thoroughput, leverage this to
					* Avoid the implementation of *backpressure* mechanisms
					* Scale easily
					* Build a system that is resilient to sudden bursts of data
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					## Contracts 
					The data in kafka topics will need to evolve.
					Choose your data-types that give you the flexibility to evolve your contracts
					
					* [Avro](https://avro.apache.org/) and [Protocol Buffers](https://developers.google.com/protocol-buffers/) are two good examples
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					## Transformations

					Give preference to ELT instead of ETL 

					* With *Extract Transform Load* sometimes we endup with partial data which leads to flaky messy data pipelines
					* With *Extract Load Transform* we try preserving the context presented in the raw data as much as possible
						* This leads to less messy data pipelines
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					## Security
					Analyse your security requirements.
					Do we have sensitive topics we don't wan't everyone connecting to?
					* Use Kafka [SASL](https://en.wikipedia.org/wiki/Simple_Authentication_and_Security_Layer) authorization mechanism
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					## Failure Handling
					Plan for failure in advance
					* Analyse your failure scenarios
					* Find your *recoverable* *non recoverable* errors and plan accordingly
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					## Coupling and Agility
					* Avoid *Ad-Hoc* pipelines
					  * Plan your data pipeline in advance
					  * Avoid reactive design (creating consumers producers as needed)
					* Avoid Loss of metadata
					  * Preserve schema information for evolutionary contracts purpose
					* Avoid extreme processing
					  * Extreme processing hurts agility
					  * Allow downstream components do the decisions
				</textarea>
			</section>						
		</section>
		<section>
			<section data-markdown>
				<textarea data-template>
					## Cross-Cluster Architectures
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					### Why cross-cluster architectures
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					* Regional and central clusters
					* Redundancy (data recovery)
					* Cloud migrations
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					### Multi cluster architectures
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Some limitations

					* High Latencies
						* Latency increases lineary with distance and the number of ops
						in the network
					* Limited bandwidh
						* WANs have less bandwith than intra datacenter comunications
					* Higher costs
						* Due the need to improve bandwidth and latency
						requirements
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Hub-and-Spokes Architecture
					![Hub and Spokes Architecture](img/hubandspokes1.png)
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					![Hub and Spokes Architecture](img/hubandspokes2.png)	
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Advantages
					* Leverage of data locality by producing always to the local cluster
					* Data mirrowed once, to the central cluster
					* Simple to deploy mirror and monitor
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Disadvantages
					* Data locality makes hard for local processor in local *A* to access
					data from local *B*
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Active-Active Architecture
					![Active-Active](img/activeactive1.png)
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Advantages
					* Leverage of data locality without scacrificing functionality
					due to limited availability of data
					* Redundancy and resilience
					* Cost effective
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Disadvantages
					* Hard to manage conflicting async read/write operations from different
					locations
					* Careful need to avoid endless replication of data
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Active-Passive Architecture	
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					![Active-Passive Architecture](img/activepassive.png)
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Advantages
					* Simplicity of implementation
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Disadvantages
					* Wast of resources
						* Since it is not actively serving traffic
					* Failover between kafka clusters harder than it looks
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Unplanned failover strategies
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Start offset applications after failover
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Auto offset reset
					* Deal with duplicate or data loss
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Replicate offsets topic
					![Topics Duplication](img/topicsreplication.png)
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Caveats
					* The replication of offsets will not work in some cases
						* Some compromises must be done
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Time-based failover
					* Version consumers on *0.10* and above have a timestamp in the message
					this can be used to control the reprocessing of messages
					* However you need to deal with data loss or duplicates
						* The window is much smaller though 
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### External offset mapping
					* Instead of replication of offsets we can map them 
					(for example to a database)
						* The window to loss/duplicate of data is even lesser
						* Higher complexity though
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### After the failover
					* Tempting to switch active to passive and resync
						* This is tricky
					* Better to
						* Become active to passive
						* Erase the old active cluster 
						* Start sync with new active
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Stretch Cluster Architecture
					* One cluster spread across several datacenters
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Advantages
					* Synchronous replication
					* All datacenters are being used (less wast of resources)
					* Protection against datacenter failures (not application failures)
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Disadvantages
					* This architecture needs three datacenters for zookeepers
						* If we only have two dc for zookeepers you'll not be able to reach
						quorum
					* Latency and bandwidth are high because of zookeeper sensitivity
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					### Mirror Maker
					A tool to replicate kafka topics between clusters
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					![Mirror Maker](img/mirrormaker.png)
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Running Mirror Maker
					```
					bin/kafka-mirror-maker 
					--consumer.config etc/kafka/consumer.properties 
					--producer.config etc/kafka/producer.properties 
					--new.consumer -num.streams=2 
					--whitelist ".*"
					```
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Mirror Maker in production
					* If using containers run it inside one
						* Better scaling
						* Better failover control
					* Monitor the *Lag*
					* Tune your Mirror Maker cluster
						* You can use `kafka-performance-producer`
						to help
						* Target `lag SLOs`
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Other replication tools
					* [uReplicaticator](https://github.com/uber/uReplicator)
					* [Confluent Replicator](https://docs.confluent.io/current/connect/kafka-connect-replicator/index.html)
					* Here in PPB we usually use a Storm Topology
						* It has all the failover and scalling capabilities we need
				</textarea>
			</section>
		</section>
		<section>
				<section data-markdown>
					<textarea data-template>
						## Kafka Producers
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						<img src="img/prodoverview.png" alt="Producers Overview" width="60%"/>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Setting up a Kafka Producer
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Configurations needed

						* bootstrap-servers - List of kafka brokers
						* key.serializer - Class responsible for *key* serialization
						* value.serializer -  Class responsible for *payload* serialization

					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Java example
						```
						Properties kafkaProps = new Properties();

						kafkaProps.put(
							"bootstrap.servers", 
							"broker1:9092,broker2:9092"
						);
						kafkaProps.put(
							"key.serializer",
							"org.apache.kafka.common.serialization.StringSerializer"
						);
						kafkaProps.put(
							"value.serializer",
							"org.apache.kafka.common.serialization.StringSerializer"
						);

						KafkaProducer producer = new KafkaProducer<String, String>(kafkaProps);
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Publishing strategies

						* Fire and Forget
						* Synchronous send
						* Asynchronous send
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Fire and forget
						```
						ProducerRecord<String, String> record = new ProducerRecord<>(
							"CustomerCountry", "Precision Products", "France"
						);
						try {
							producer.send(record);
						} catch (Exception e) {
							e.printStackTrace();
						}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Synchronous send
						```
						ProducerRecord<String, String> record = new ProducerRecord<>(
							"CustomerCountry", "Precision Products", "France"
						);
						try {
							producer.send(record).get();
						} catch (Exception e) {
							e.printStackTrace();
						}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Async send

						* You define a callback to handle the message result

						```
						private class DemoProducerCallback implements Callback {
							@Override
							public void onCompletion(
								RecordMetadata recordMetadata, 
								Exception e
							){
								if (e != null) {
									e.printStackTrace();
								}
							}
						}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* And set this callback in the *send* method
						```
						ProducerRecord<String, String> record = new ProducerRecord<>(
							"CustomerCountry", "Precision Products", "France"
						);
						try {
							producer.send(record,new DemoProducerCallback());
						} catch (Exception e) {
							e.printStackTrace();
						}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Producers configurations
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### acks

						* acks = 0 -- Producer will not wait for broker reply
						* acks = 1 -- Producer will receive notification as soon as leader replica acknowledge
						the message
						* acks = all --Producer will receive notification as soon as all in-sync replicas
						receive the message
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Acks trade-off

						* The less you care for broker responses the higher the risk for loss of messages
						* The less you care for broker responses the higher the throughput of your system
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Buffer memory (buffer.memory)

						* Buffer used by the producer. 
						* If the buffer is filled and no more messages are possible to hold an exception is
						thrown.
						* Filling of buffer usually means broker not being able to keep up with production rate
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Compression Type (compression.type)
						
						* By default messages are uncompressed
						* This parameter can be set to:
							* [Snappy](https://en.wikipedia.org/wiki/Snappy_(compression))
							* [LZ4](https://en.wikipedia.org/wiki/LZ4_(compression_algorithm))
							* [Gzip](https://en.wikipedia.org/wiki/Gzip)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Retries 
						
						* Number of retries the producer will atempt before throwing an exception
						* Producer will hold 100ms by default between atempts
							* This can be overrided with *retry.backoff.ms* parameter
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Batch Size (batch.size)

						* For performance reasons the produces batch the messages to be send 
						to a specific partition
						* This parameter specifies the size of this buffer in bytes (not in messages)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Linger milliseconds (linger.ms)

						* Latency is a concern. We need a way to guarantee that messages are sent even
						if the batch buffer is not completly filled
						* *linger.ms* is the time in milliseconds that the producer will wait
						for batch buffer completion.
						* After this time the messages on the batch are sent anyway.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Client ID (client.id)

						* *client.id* is just a tag sent by the producer for the brokers be able
						to identify the client
							* Used for logging, metrics and quotas
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Max Inflight Requests/Connection (max.in.flight.requests.per.connection)

						* This controls the maximum number of pending requests in flight
							* Increasing this will increase throughput while increasing also memory footprint
							* Setting to 1 will guarantee that messages will be sent to kafka in order
							while sacrificing throughput
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Timeouts

						* *timeout.ms* -- Controls the time the broker will wait for in-sync replicas to acknowledge the message
						in order to meet the acks configurationâthe broker will return an error if the time
						elapses without the necessary acknowledgments.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* *request.timeout.ms* -- Controls how long the producer will wait for a reply from the server
						when sending data.
						* *metadata.fetch.timeout.ms* -- Controls how long will wait while requesting 
						metadata such as the current leaders for the partitions.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Max Block milliseconds (max.block.ms)

						* Controls how long the producer will block when calling *send()* and
when explicitly requesting metadata via *partitionsFor()*
						* When this timeout is reached an exception is thrown
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Max Request Size (max.request.size)

						* This parameter sets the maximum size of a produce request
							* Note that most broker configuration will not accept messages with payload 
							higher than 1MB (*message.max.bytes*)
						
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Receive/Send Buffer bytes (receive.buffer.bytes/send.buffer.bytes)

						* By default they are set with -1 which means use the default OS 
						configurations
							* We should review this parameter and increase it when publishing/consuming from/to
							different datacenters
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Serialize with Avro
						![Avro Schema](img/avroschema.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
							```
							Properties props = new Properties();
							props.put("bootstrap.servers", "localhost:9092");
							props.put(
								"key.serializer",
								"io.confluent.kafka.serializers.KafkaAvroSerializer"
							);
							props.put(
								"value.serializer",
								"io.confluent.kafka.serializers.KafkaAvroSerializer"
							);
							
							props.put("schema.registry.url", schemaUrl);
							String topic = "customerContacts";
							int wait = 500;
							Producer<String, Customer> producer = new KafkaProducer<String,
	Customer>(props);
							while (true) {
								Customer customer = CustomerGenerator.getNext();
								System.out.println("Generated customer " +
								customer.toString());
								ProducerRecord<String, Customer> record =
									new ProducerRecord<>(
										topic, customer.getId(), 
										customer
								);
								producer.send(record);
								```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Other payloads options

						* [JSON](https://www.json.org/)
						* [Protocol Buffers](https://developers.google.com/protocol-buffers/)
						* [Thrift Protocol](https://thrift.apache.org/)

						* For more analysis on pros and cons of these different protocols you can check 
						[chapter 4 of DDIA](https://dataintensive.net/)

					</textarea>
				</section>
			</section>
		<section>
				<section data-markdown>
					<textarea data-template>
						## Kafka Consumers
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						![Single consumer](img/consumer1.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
							![Single consumer](img/consumer2.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
							![Single consumer](img/consumer3.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
							![Single consumer](img/consumer4.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
							<img src="img/consumer5.png" width="60%"/>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Same Consumer Group

						* The same consumer group enable easy implementation of:
							* Load balancing
							* Failover mechanisms
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Different Consumer Group

						* Different consumer groups enables:
							* Independent consumption from different applications
							* This leads to better scalling capabilities.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### A simple java consumer

						```
						Properties props = new Properties();
						props.put("bootstrap.servers", "broker1:9092,broker2:9092");
						props.put("group.id", "CountryCounter");
						
						props.put(
							"key.deserializer",
							"org.apache.kafka.common.serialization.StringDeserializer"
						);
						props.put(
							"value.deserializer",
							"org.apache.kafka.common.serialization.StringDeserializer"
						);
						
						KafkaConsumer<String, String> consumer = new KafkaConsumer<String,
						String>(props);
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Subscribing a topic
						```
						consumer.subscribe(
							Collections.singletonList(
								"customerCountries"
							)
						);
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Subscribing by pattern
						```
						consumer.subscribe(
							Collections.singletonList(
								"topic.type.*"
							)
						);
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### The consumer loop
						```
						try {
							while (true) {
								ConsumerRecords<String, String> records = consumer.poll(100);
								for (ConsumerRecord<String, String> record : records)
								{
									log.debug("
										topic = %s, 
										partition = %s, 
										offset = %d,
										customer = %s, 
										country = %s\n",
										record.topic(), 
										record.partition(), 
										record.offset(),
										record.key(), 
										record.value()
									);
									
									int updatedCount = 1;
									
									if (custCountryMap.countainsValue(record.value())) {
										updatedCount = custCountryMap.get(record.value()) + 1;
									}
								
									custCountryMap.put(record.value(), updatedCount)
									JSONObject json = new JSONObject(custCountryMap);
									System.out.println(json.toString(4))
								}
							}
						} finally {
							consumer.close();
						}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Notes on thread safety
						
						* You canât have multiple consumers that belong to the same group
						in one thread.
						* You canât have multiple threads safely use the same consumer.
						* One consumer per thread is the rule.
						* To run multiple consumers in the same group in one application, you will
						need to run each in its own thread.
						* See more details in [this confluent tutorial](https://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0-9-consumer-client/)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Main consumer configurations
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Fetch minimum bytes (fetch.min.bytes)

						* This will specify the buffer in bytes that will be allocated to fetch records
						* This will impact the amount of data we will be able to fetch on each `pool()`
						call
						* Higher values will reduce the amount of pool calls because less *forth and back* 
						communication is needed
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Fetch maximum wait (fetch.max.wait.ms)

						* This parameter sets the maximum amount of time (in milliseconds) that
						the request call can be blocked.
						* If the minimum bytes is not reached the data batched is returned anyway
						*
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Max partition fetch bytes (max.partition.fetch.bytes)

						* This controls the ammount of data sent by the broker on each partition
						* The default is 1MB
							* This means that if you got 20 partitions you'll need 20Mb of memory
						* This parameter must be set accordingly with the broker parameter *max.message.size*
							* Otherwise you can endup in a failure loop because you'll be not able to consume a message
							and will stuck in error
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Session Timeout milliseconds (session.timeout.ms)

						* This parameter sets the maximum time that the consumer can be without comunication with
						the coordinator.
							* If the timeout is reached the coordinator will launch a rebalance to allocate partitions
							from this (now considered dead) consumer to other consumers in the group
						* The parameter *heartbeat.interval.ms* defines the interval of heartbeats from the consumer
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Auto offset reset (auto.offset.reset)

						* When no offset (or invalid) is found on the *__consumers* topic a
						default policy is applied
							* *earliest* -- If set with this value it will start consuming from the beginning
							* *latest*   -- If set with this value it will start consuming from the most recent
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Auto commit (enable.auto.commit)

						* This is a boolean parameter that will enable/disable the automatic submition of 
						consumed offsets from the consumer
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Partition Assignment Strategy (partition.assignment.strategy)

						* This parameter holds the name of the class that will be responsible to
						define the way partitions are assigned to consumers
						* There are two default implementations:
							* Range 
							* RoundRobin
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Range Partition Assignment Strategy
						* Assigns to each consumer a consecutive subset of partitions
						 from each topic it subscribes to:
						 	* If consumers C1 and C2 are subscribed to two topics, T1 and
							 T2, and each of the topics has three partitions, then C1 will be assigned partitions
							 0 and 1 from topics T1 and T2, while C2 will be assigned partition 2 from those
							 topics
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### RoundRobin Partition Assignment Strategy
						
						* Takes all the partitions from all subscribed topics and assigns them to consumers
						sequentially, one by one.
							* If C1 and C2 described previously used RoundRobin assignment, 
							C1 would have partitions 0 and 2 from topic T1 and partition 1 from
							topic T2. C2 would have partition 1 from topic T1 and partitions 0 and 2 from
							topic T2
							
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Client ID (client.id)
						
						* The same purpose of the *client.id* parameter in the producer 
						configuration
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Maximum pool records (max.poll.records)

						* Will define the maximum amount of *ConsumerRecords* returned by *pool* call.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Commits and offsets
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Can lead to

						* Reprocessing of messages
						* Loss of messages
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Reprocessing of messages
						![Reprocessing of Messages](img/reprocessmessages.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Loss of messages
						![Loss of messages](img/lossmessage.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Automatic Commit

						* This will be done periodically with the highest value returned by *pool*
						call.
							* The period of submission is defined by the parameter *auto.commit.interval.ms*
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Manual sync commit

						* Disable the automatic commit of offsets by setting the *auto.commit.offset* 
						to *false*
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						```
							ConsumerRecords<String, String> records = consumer.poll(100);
							for (ConsumerRecord<String, String> record : records){
								System.out.printf("
								topic = %s, 
								partition = %s, 
								offset =
								%d, customer = %s, 
								country = %s\n",
							record.topic(), 
							record.partition(),
							record.offset(), 
							record.key(), 
							record.value());
							}
							try {
								consumer.commitSync();
							} catch (CommitFailedException e) {
								log.error("commit failed", e)
							}
						```
					</textarea>
				</section>
				<section data-markdown>
						<textarea data-template>
							#### Manual Async commit

							```
							consumer.commitAsync();
							```
						</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Manual Async Commit with callback
						```
						consumer.commitAsync(new OffsetCommitCallback() {
							public void onComplete(
								Map<TopicPartition,
								OffsetAndMetadata> offsets, 
								Exception exception
							) {
								if (e != null)
									log.error("Commit failed for offsets {}", offsets, e);
								}
							});
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Combine Sync/Async Pattern
						```
						try {
							while (true) {
								ConsumerRecords<String, String> records = consumer.poll(100);
								for (ConsumerRecord<String, String> record : records) {
									System.out.printf("topic = %s, partition = %s, offset = %d,
									customer = %s, country = %s\n",
									record.topic(), record.partition(),
									record.offset(), record.key(), record.value());
								}
								consumer.commitAsync();
							}
							} catch (Exception e) {
								log.error("Unexpected error", e);
							} finally {
								try {
									consumer.commitSync();
								} finally {
									consumer.close();
								}
							}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Custom offset commit
						```
						while (true) {
							ConsumerRecords<String, String> records = consumer.poll(100);
							for (ConsumerRecord<String, String> record : records)
							{
								System.out.printf("
									topic = %s,
									partition = %s, 
									offset = %d,
									customer = %s, 
									country = %s\n",
									record.topic(), 
									record.partition(), 
									record.offset(),
									record.key(), 
									record.value()
								);
								
								currentOffsets.put(
									new TopicPartition(record.topic(),record.partition()), 
									new OffsetAndMetadata(record.offset()+1, "no metadata")
								);


								if (count % 1000 == 0)
									consumer.commitAsync(currentOffsets, null);
								count++;
							}
						}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Rebalance Listeners

						* Usefull to implement cleanup routines when an event of partition rebalancing
						happens
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### The contract
						* Is defined in the *ConsumerRebalanceListener* and has two major callbacks

						```
						public void onPartitionsRevoked(Collection<TopicPartition> partitions)
						public void onPartitionsAssigned(Collection<TopicPartition> partitions)
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Implementation example
						```
						class HandleRebalance implements ConsumerRebalanceListener {
							public void onPartitionsAssigned(
								Collection<TopicPartition>partitions
							) {}
							
							public void onPartitionsRevoked(
								Collection<TopicPartition> partitions
							) {
								System.out.println("Lost partitions in rebalance.
								Committing current
								offsets:" + currentOffsets);
								consumer.commitSync(currentOffsets);
							}
						}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Use our rebalance listener

						```
						consumer.subscribe(topics, new HandleRebalance());
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Consuming records with specific offsets
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Implement the rebalance listener
						```
						public class SaveOffsetsOnRebalance implements ConsumerRebalanceListener {
							public void onPartitionsRevoked(Collection<TopicPartition>
							partitions) {
								commitDBTransaction();
							}
							public void onPartitionsAssigned(Collection<TopicPartition>
							partitions) {
								for(TopicPartition partition: partitions)
									consumer.seek(partition, getOffsetFromDB(partition));
							}
						}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Set the rebalance in the consumer subscription
						```
						consumer.subscribe(
							topics, 
							new SaveOffsetOnRebalance(consumer)
						);
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Set offsets and consumer loop
						```
						consumer.poll(0);
						for (TopicPartition partition: consumer.assignment())
						consumer.seek(partition, getOffsetFromDB(partition));
						while (true) {
							ConsumerRecords<String, String> records =
							consumer.poll(100);
							for (ConsumerRecord<String, String> record : records)
							{	
								processRecord(record);
								storeRecordInDB(record);
								storeOffsetInDB(record.topic(), record.partition(),
								record.offset());
							}
							commitDBTransaction();
						}
						```
					</textarea>
				</section>
		</section>
		<section>
				<section data-markdown>
					<textarea data-template>
						## Kafka Internals
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Cluster membership

						* The cluster information can be checked in zookeeper

						```
						ls /<kafka_root>/brokers/ids
						[0]
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* To get information regarding the broker [0], do a *znode get*
						```
						get /<kafka_root>/brokers/ids/0
								{
									"listener_security_protocol_map":{
										"PLAINTEXT":"PLAINTEXT"
									},"endpoints":["PLAINTEXT://localhost:9092"],
									"jmx_port":-1,
									"host":"localhost",
									"timestamp":"1560882654942",
									"port":9092,
									"version":4
								}
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Getting the Controller Node

						```
						get /<kafka_root>/controller
						{"version":1,"brokerid":0,"timestamp":"1560882655203"}
						```


					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Replication
						
						* Kafka partitions are represented physically in terms of replicas
						* There are two types of replicas
							* Leader replica
							* Follower replica
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* Follower replicas issue fetch requests
						* Leader replica keep track of the fech requests from each replica
						and validate which of them are in-sync based on the property *replica.lag.time.max.ms*
							* If a follower replica don't send a fetch request in the timeout defined by the 
							previous parameter is considered *out of sync*
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* We also have the *prefered leader* 
							* which consists of the leader replica at topic creation time 
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Why this matters?

						* By default, Kafka is with *auto.leader.rebalance.enable=true*, 
						which will check if the preferred leader replica is not the current leader but is in-sync 
						and trigger leader election to make the preferred leader the current leader.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Requests Processing

						Kafka has an internal binary protocol to handle the requests between brokers
						it is [described here](http://kafka.apache.org/protocol.html)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* All requests have the following standard headers
							* *Request type* (also called API key)
							* *Request version* (so the brokers can handle clients of different versions and
							respond accordingly)
							* *Correlation ID* a number that uniquely identifies the request and also appears in
							the response and in the error logs (the ID is used for troubleshooting)
							* *Client ID* used to identify the application that sent the request
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Requests processor arquitecture
						![Requests Processor](img/requestsprocessor.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Processor Queues

						* The requests processor has two processor queues
							* One for *Fetch Requests* sent by consumers and follower replicas when they read 
							messages from Kafka brokers.
							* One for *Produce Requests* sent by producers and contain messages the clients write to Kafka brokers.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Client routing requests
						![Client Routing Requests](img/clientroutingrequests.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* Clients issue *Metadata Requests* to retrieve meta information from the cluster
							* Like which is the leader for the partition *A* of topic *B*
						* These *Metadata Requests* are cached by the clients based on a configuration 
						parameter *metadata.max.age.ms*
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Producer/Broker/Consumer Diagram
						![Producer Broker Consumer](img/producerbrokerconsumer.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Consumer messages availability
						![Messages available](img/consumermessages.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Other Kafka Protocol Messages

						* The kafka protocol supports around 20 other message types, namely:
							* OffsetCommitRequest
								* Introduced to support consumer offsets management in kafka
								instead of zookeeper
							* OffsetFetchRequest
							* ListOffsetsRequest 
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Physical storage

						* Where are the log files stored?
							* In the path defined by the configuration parameter *log.dirs*
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Partition Allocation

						* Supose you got a cluster of 3 brokers
						* Supose you got a topic with 10 partitions and replication factor of 3
							* This means a total of 30 partition replicas need to be stored

					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						##### Goals to achieve

						* Distribute evenly the replicas across the brokers.
							* In this case we would like to have 10 replicas per broker
						* Avoid replicas for the same partition on the same broker
							* The means that for all the 10 replicas on the broker they 
							relate to non repeated partitions
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* If the brokers have rack information, then assign the replicas for 
						each partition to different racks if possible.
							* Available in Kafka release 0.10.0 and higher
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						![Rack Distribution](img/rackbrokers.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* Here in PPB we can achieve the same by building our 
						pipeline in a way that our brokers would end up on different hypervisors
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### File Management
						
						* The data of a *partition replica* lives inside a *log* file and they are
						divided into *segments*.
						* They rotate based on topic configurations
						* Rotated segments are deleted or compacted based on topic policy 
						* The segment that is being used for write operations is called *active segment*
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### File format
						
						* The file format is very close with the in memory representation.
							* This enables a *zero-copy* strategy when sending data to consumers
							* Avoid recompression of already compressed data from the producer
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						![Log file format](img/messageinlog.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Index File

						* Kafka needs to quickly retrieve position of message based on the offset
						* Kafka has an index file per partition which
							* Maps the offset to the segment and position within the file
							where the message holds
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
		</section>
		<section>
				<section data-markdown>
					<textarea data-template>
						## Kafka Metrics
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### JMX Metrics
						
						* Kafka has application level JMX exposed metrics
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Under replicated partitions
						```
							MX MBean: 
							kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions
							
							Value range: 
							Integer, zero or greater
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* This measurement, provided on each broker in a cluster, 
						gives a count of the number of partitions for which the
						broker is the leader replica, where the follower replicas are not caught up.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						```
							kafka-topics.sh --zookeeper zoo1.example.com:2181/kafka-cluster --describe
							--under-replicated
							Topic: topicOne Partition: 5 Leader: 1 Replicas: 1,2 Isr: 1 
							Topic: topicOne Partition: 6 Leader: 3 Replicas: 2,3 Isr: 3
							Topic: topicTwo Partition: 3 Leader: 4 Replicas: 2,4 Isr: 4
							Topic: topicTwo Partition: 7 Leader: 5 Replicas: 5,2 Isr: 5
							Topic: topicSix Partition: 1 Leader: 3 Replicas: 2,3 Isr: 3
							Topic: topicSix Partition: 2 Leader: 1 Replicas: 1,2 Isr: 1
							Topic: topicSix Partition: 5 Leader: 6 Replicas: 2,6 Isr: 6
							Topic: topicSix Partition: 7 Leader: 7 Replicas: 7,2 Isr: 7
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* The previous command shows consistently that the broker with id 2 is with problems
						keeping up in sync with the rest of the cluster. 
						* A more in depth analysis should be done on this broker
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Active controller count
						
						```
						JMX MBean:
						kafka.controller:type=KafkaController,name=ActiveControllerCount
						
						Value range:
						Zero or one
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* This metric is a *boolean* value representing if the broker is currently
						the controller of the cluster
							* The cluster should have just one value with 1
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Request Handler idle ratio

						* Kafka has two thread pools to process clients request
							* Network Handlers - Used for network I/O
							* Request Handlers - Used for disk I/O
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* As such, as the brokers get more heavily loaded, 
						there is a significant impact on this thread pool
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						```
						JMX MBean:
						kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent
						Value range:
						Float, between zero and one inclusive
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### All topics bytes in

						* The all topics bytes in rate, expressed in bytes per second, is useful as a measurement
						of how much message traffic your brokers are receiving from producing clients. 
						* This is a good metric to trend over time to help you determine when you need to expand 
						the cluster or do other growth-related work.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						```
							JMX MBean kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec
							Value range
							Rates as doubles, count as integer
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					</textarea>
				</section>
		</section>
		<section>
		<section data-markdown>
			<textarea data-template>
				## Administering Kafka
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				### Topic Operations
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				Creating a topic
				```
				kafka-topics 
					--create 
					--zookeeper zoo1.example.com:2181/kafka-cluster
					--topic my.topic 
					--replication-factor 1 
					--partitions 1 
					--config "cleanup.policy=compaction" 
					--config "delete.retention.ms=100"  
					--config "segment.ms=100" 
					--config "min.cleanable.dirty.ratio=0.01"
				```

				dirty ratio = the number of bytes in the head / total number of bytes in the log(tail + head)
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				Deleting a topic
				```
				kafka-topics.sh 
					--zookeeper zoo1.example.com:2181/kafka-cluster
					--delete --topic my-topic
				```
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				List topics
				```
				kafka-topics.sh 
				--zookeeper zoo1.example.com:2181/kafka-cluster
				--list
				```	
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				Describe topics
				```
				kafka-topics.sh --zookeeper zoo1.example.com:2181/kafka-cluster --describe
				Topic:other-topic PartitionCount:8 ReplicationFactor:2 Configs: 
				Topic:other-topic Partition: 0     Replicas: 1,0       Isr: 1,0
				Topic:other-topic Partition: 1     Replicas: 0,1       Isr: 0,1
				Topic:other-topic Partition: 2     Replicas: 1,0       Isr: 1,0
				Topic:other-topic Partition: 3     Replicas: 0,1       Isr: 0,1
				Topic:other-topic Partition: 4     Replicas: 1,0       Isr: 1,0
				Topic:other-topic Partition: 5     Replicas: 0,1       Isr: 0,1
				Topic:other-topic Partition: 6     Replicas: 1,0       Isr: 1,0
				Topic:other-topic Partition: 7     Replicas: 0,1       Isr: 0,1
				```	
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				Describe topic partitions not in sync
				```
				kafka-topics.sh --zookeeper zoo1.example.com:2181/kafka-cluster
				--describe 
				--under-replicated-partitions

				Topic: other-topic Partition: 2 Leader: 0 Replicas: 1,0 Isr: 0
				Topic: other-topic Partition: 4 Leader: 0 Replicas: 1,0 Isr: 0
				```
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				### Consumer Groups
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				List consumer groups
				* Old kafka clusters
				```
				kafka-consumer-groups.sh 
				--zookeeper zoo1.example.com:2181/kafka-cluster 
				--list
				
				console-consumer-79697
				myconsumer
				```

				* New kafka clusters
				```
				./kafka-consumer-groups.sh 
				--bootstrap-server localhost:9092 -list
				```
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
			Describe consumer groups
			```
			kafka-consumer-groups.sh 
			--zookeeper zoo1.example.com:2181/kafka-cluster
			--describe --group testgroup
			GROUP      TOPIC    PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG OWNER
			testgroup my-topic 0         1688           1688           0   testgroup_host1.example.com-1478188622741-7dab5ca7-0
			testgroup my-topic 1         1418           1418           0   testgroup_host1.example.com-1478188622741-7dab5ca7-0
			testgroup my-topic 2         1314           1315           1   testgroup_host1.example.com-1478188622741-7dab5ca7-0
			testgroup my-topic 3         2012           2012           0   testgroup_host1.example.com-1478188622741-7dab5ca7-0
			testgroup my-topic 4         1089           1089           0   testgroup_host1.example.com-1478188622741-7dab5ca7-0
			testgroup my-topic 5         1429           1432           3   testgroup_host1.example.com-1478188622741-7dab5ca7-0
			testgroup my-topic 6         1634           1634           0   testgroup_host1.example.com-1478188622741-7dab5ca7-0
			testgroup my-topic 7         2261           2261           0   testgroup_host1.example.com-1478188622741-7dab5ca7-0
			```
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				* Delete consumer group
				* If you don't provide the `--topic` argument it will delete the consumer group for
				all the topics.

				```
				kafka-consumer-groups.sh 
				--zookeeper zoo1.example.com:2181/kafka-cluster 
				--delete 
				--group testgroup
				--topic my-topic
				
				Deleted all consumer group information for group testgroup topic
				my-topic in zookeeper.

				```
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
					### Offset management
					#### Some old deprecated tools
					* Export offsets for a consumer group

					```
					kafka-run-class.sh kafka.tools.ExportZkOffsets
					--zkconnect zoo1.example.com:2181/kafka-cluster 
					--group testgroup
					--output-file offsets
					```
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
					* Import offsets for a consumer group

					```
					kafka-run-class.sh kafka.tools.ImportZkOffsets 
					--zkconnect zoo1.example.com:2181/kafka-cluster 
					--input-file offsets
					```
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				### Dynamic topics configuration
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				Changing topic retention
				
				
					kafka-configs.sh 
					--zookeeper zoo1.example.com:2181/kafka-cluster
					--alter 
					--entity-type topics 
					--entity-name my-topic 
					--add-config retention.ms=3600000
				
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				Describe topic configurations

					./kafka-configs.sh 
					--zookeeper localhost:2181/localkafka 
					--describe 
					--entity-type topics 
					--entity-name powers.stream.fip
					
					Configs for topics:my-topic are
					retention.ms=3600000,segment.ms=3600000
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				Remove topic configuration
				
					kafka-configs.sh 
					--zookeeper zoo1.example.com:2181/kafka-cluster
					--alter 
					--entity-type topics 
					--entity-name my-topic
					--delete-config retention.ms
					
					Updated config for topic: "my-topic"
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
				### Partition Management
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
					#### Rebalance partition leadership

					* Globalwide topic balance leadership

							kafka-preferred-replica-election.sh 
							--zookeeper zoo1.example.com:2181/kafka-cluster
							
							Successfully started preferred replica election for partitions
							Set([my-topic,5], [my-topic,0], [my-topic,7], 
							[my-topic,4],[my-topic,6], [my-topic,2], 
							[my-topic,3], [my-topic,1])
			</textarea>
		</section>
		<section data-markdown>
			<textarea data-template>
					* For large clusters this command is not possible due a 1MB zookeeper request limit
					* You need to break down into several elections based on files
					
						{
							"partitions":
							[
							{"topic": "topic1", "partition": 0},
							{"topic": "topic1", "partition": 1},
							{"topic": "topic1", "partition": 2},
							{"topic": "topic2", "partition": 0},
							{"topic": "topic2", "partition": 1}
							]
						}
			</textarea>
		</section>
			<section data-markdown>
				<textarea data-template>
						#### The `kafka auto.leader.rebalance.enable` flag
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					* If possible this flag should be true to avoid manual intervention on the cluster
					* There are significant performance impacts caused by the automatic balancing module, and it can cause a lengthy pause in client traffic for larger
					clusters.
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Reassign partition replicas
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					* First create a `json` file containing the topics for which you want the replicas reassigned

						```
						{
							"topics": [
								{
									"topic": "my-topic"
								}
							],
							"version": 1
						}
						```
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					* Then run the following command to generate a new assignment purposal

							kafka-reassign-partitions.sh 
							--zookeeper zoo1.example.com:2181/kafka-cluster 
							--generate
							--topics-to-move-json-file topics.json 
							--broker-list 0,1
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					* The previous command will generate a json output with a proposal of reasignment.
					* Use this proposal to reassign the replicas

							kafka-reassign-partitions.sh 
							--zookeeper zoo1.example.com:2181/kafka-cluster 
							--generate --topics-to-move-json-file topics.json 
							--broker-list 0,1

				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Note
					
					* When removing many partitions from a single broker, such as if
that broker is being removed from the cluster, it is a best practice:
						* To shut down and restart the broker before starting the reassignment.				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>

					#### Why?

					* This will move leadership for the partitions on that particular
					broker to other brokers in the cluster (as long as automatic leader
					elections are not enabled). This can significantly increase the perâ
					formance of reassignments and reduce the impact on the cluster as
					the replication traffic will be distributed to many brokers.
						
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Changing replication factor
					* Consider the following topic
					
							{
								"partitions": [
									{
									"topic": "my-topic",
									"partition": 0,
									"replicas": [1]
									}
								],
								"version": 1
							}
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					* By changing the previous json file into
					
						{
							"partitions": [
								{
									"partition": 0,
									"replicas": [1,2],
									"topic": "my-topic"
								}
							],
							"version": 1
						}

					* You'll be able to increase the replication factor of a topic
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
						* Note that this is an undocumented functionality of the tool and may be deprecated in the future
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Console Producer

					* Enable you to quickly test the producition to a topic

					```
					kafka-console-producer.sh 
						--broker-list <kafka1,kafka2:<port>> 
						--topic <topic>
					```
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Console consumer
					
					* Enable you to quickly consume from a kafka topic
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					##### Old way

					```
					kafka-console-consumer.sh 
					--zookeeper <zookeeper:port/path> 
					--topic my-topic
					```

					* If you want to consume from the beginning you need to add another parameter 
					
					```
					kafka-console-consumer.sh 
					--zookeeper <zookeeper:port/path> 
					--topic my-topic
					--from-beginning
					```

				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### New way

					```
					kafka-console-consumer.sh 
					--bootstrap-server <kafka:port> 
					--topic my-topic
					```
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Analyse log segments

					* Print the log in human readeable form
						
						```
						kafka-run-class.sh 
						kafka.tools.DumpLogSegments 
							--files <logfile.log>
						```
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					* If you also want the data inside the log 
					
					```
					kafka-run-class.sh 
					kafka.tools.DumpLogSegments 
						--files <logfile.log>
						--print-data-log
					```
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					* To validate the log is not corrupted

					```
					kafka-run-class.sh 
					kafka.tools.DumpLogSegments 
						--files <indexfile.index>,<logfile.log>
						--index-sanity-check
					```
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
					#### Replica verification
					
					```
					kafka-replica-verification.sh 
					--broker-list <kafka1,kafka2:port>
					--topic-white-list '<topic_regex>'
					```
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
				</textarea>
			</section>
			<section data-markdown>
				<textarea data-template>
				</textarea>
			</section>
	</section>
	<section>
				<section data-markdown>
					<textarea data-template>
						## Kafka Tinkering	
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Prepare your environment
						You can tinker with kafka by doing one of the following
						* Download Kafka and manually start kafka and zookeeper (this is actually a nice exercise)
						* Or you can run the containers that were provided 
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### The manual approach
						* Download kafka from [here](http://mirrors.up.pt/pub/apache/kafka/2.2.1/kafka_2.12-2.2.1.tgz)
						* Run 
						
						```
						wget http://mirrors.up.pt/pub/apache/kafka/2.2.1/kafka_2.12-2.2.1.tgz 
						&& tar -xvf kafka_2.12-2.2.1.tgz
						
						```
						
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### The manual approach
						* Now you need to go into kafka directory and run the following two commands in sequence
						```
							./bin/zookeeper-server-start.sh config/zookeeper.properties
							./bin/kafka-server-start.sh config/server.properties
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### The container based approach

						* We can also follow a container based approach in which the setup is already
						done in [Dockerfiles](https://docs.docker.com/engine/reference/builder/)

						* The first thing you need to do is to clone the provided git repo
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### First build the images
						* First run the following to build the images
						```
						cd centos && make build && cd ..
						cd java && make build && cd ..
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
							* With the second base image you are able to build your kafka containers
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
							* To easily bootstrap dev environments we use
							[docker-compose](https://docs.docker.com/compose/reference/build/) and their DSL
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						Bootstrap kafka environment with `docker-compose`
						```
						docker-compose -f compose/kafka-env.yml build
						docker-compose -f compose/kafka-env.yml up
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* Now list your docker images with `docker images`
						```
						REPOSITORY          TAG                 IMAGE ID            CREATED      
						compose_cassandra   latest              c242778cee7e        3 minutes ago
						compose_kafka       latest              3d4686884967        4 minutes ago
						```
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						* You also have your container running, check this by running
						`docker ps`
						```
						CONTAINER ID        IMAGE               COMMAND                  CREATED
						219b05b407a2        compose_kafka       "/bin/sh -c /opt/staâ¦"   5 seconds ago
						1593ff61df27        compose_cassandra   "/opt/start-cassandrâ¦"   5 seconds ago
						```
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
						* Access your containers with
						```
						docker exec -it <containerId> <shell>
						docker exec -it 219b05b407a2 bash
						```

						* For [alpine](https://hub.docker.com/_/alpine) based containers you would replace `bash` with `ash`
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
						#### Manual vs Docker based approach

						* Manual approach is simpler, straightforward. 
						* Manual approach is not reproductible
						* Manual approach is harder to build different combinations tech stacks
						* Local Cluster setup can be automated in docker and docker compose
						scripts and then shared among people

					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
							
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						
					</textarea>
				</section>
			</section>
		</div>
	</div>

		<script src="js/reveal.js"></script>

		<script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				hash: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true },
					{ src: 'plugin/search/search.js', async: true },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
